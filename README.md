# Text-to-SQL Agent: Agentic AI Application

A natural language interface for querying SQL databases and creating visualizations using AI agents powered by LangChain and OpenAI.

ğŸš€ **[Live Demo on Streamlit Cloud](https://text-to-sql-agent-banty2vkw4pzy22inkghl7.streamlit.app/)** ğŸš€

## What This Project Does

This application enables users to interact with an e-commerce SQL database using natural language queries. It leverages two specialized AI agents:

1. **SQL Agent**: Converts natural language questions into SQL queries and retrieves data
2. **Python Agent**: Generates interactive Plotly visualizations based on query results

The system maintains conversation context, allowing for follow-up questions and iterative data exploration without repeating information.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”€â”€â”
â”‚                         Streamlit Web UI                             â”‚
â”‚                      (streamlit_app.py)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                        â”‚
             â”‚ User Query                             â”‚ Display Results
             â–¼                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Query Router                                    â”‚
â”‚                                                                      â”‚
â”‚  Checks for keywords: "plot", "graph", "chart", "diagram"            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                  â”‚
    Visualization                        Text Query
    Keywords Found                       Only
             â”‚                                  â”‚
             â–¼                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    SQL Agent            â”‚        â”‚    SQL Agent            â”‚
â”‚  (src/llm_agent.py)     â”‚        â”‚  (src/llm_agent.py)     â”‚
â”‚                         â”‚        â”‚                         â”‚
â”‚  â€¢ OpenAI GPT-4         â”‚        â”‚  â€¢ OpenAI GPT-4         â”‚
â”‚  â€¢ LangChain            â”‚        â”‚  â€¢ LangChain            â”‚
â”‚  â€¢ SQLDatabaseToolkit   â”‚        â”‚  â€¢ SQLDatabaseToolkit   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                   â”‚
           â”‚ SQL Query                         â”‚ SQL Query
           â–¼                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚   SQLite Database       â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   (ecommerce)           â”‚
â”‚                         â”‚
â”‚  Tables:                â”‚
â”‚  â€¢ users                â”‚
â”‚  â€¢ orders               â”‚
â”‚  â€¢ order_items          â”‚
â”‚  â€¢ products             â”‚
â”‚  â€¢ inventory_items      â”‚
â”‚  â€¢ distribution_centers â”‚
â”‚  â€¢ events               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Query Results
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Python Agent          â”‚
â”‚  (src/llm_agent.py)     â”‚
â”‚                         â”‚
â”‚  â€¢ OpenAI GPT-4         â”‚
â”‚  â€¢ PythonREPLTool       â”‚
â”‚  â€¢ Plotly Library       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Python Code
           â”‚ (Plotly)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Visualization Engine   â”‚
â”‚  (src/helper.py)        â”‚
â”‚                         â”‚
â”‚  â€¢ Code extraction      â”‚
â”‚  â€¢ Safe execution       â”‚
â”‚  â€¢ Chart rendering      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Interactive Chart
           â–¼
      [Display to User]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conversation Memory    â”‚
â”‚  (SQLChatMessageHistory)â”‚
â”‚                         â”‚
â”‚  â€¢ session_history.db   â”‚
â”‚  â€¢ Context preservation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Interaction Flow

1. **User Input** â†’ Streamlit captures query
2. **Query Analysis** â†’ Check for visualization keywords
3. **SQL Agent** â†’ Converts query to SQL, executes against database
4. **Context Management** â†’ Maintains conversation history
5. **Python Agent** (if visualization) â†’ Generates Plotly code
6. **Display** â†’ Shows results/charts in Streamlit UI

---

## Project Structure

```
text-to-sql-agent/
â”œâ”€â”€ streamlit_app.py     # Main Streamlit application (entry point)
â”œâ”€â”€ setup_database.py    # Database initialization script
â”œâ”€â”€ .python-version      # Python 3.10 specification for version managers
â”œâ”€â”€ .env.example         # Environment variables template
â”œâ”€â”€ .env                 # Your local secrets (not in git)
â”œâ”€â”€ .gitignore           # Git ignore file
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ ecommerce            # SQLite database file (created by setup script)
â”œâ”€â”€ session_history.db   # Conversation history storage
â”œâ”€â”€ src/                 # Supporting modules
â”‚   â”œâ”€â”€ __init__.py      # Package initialization
â”‚   â”œâ”€â”€ config.py        # Configuration loader (.env + Streamlit secrets)
â”‚   â”œâ”€â”€ helper.py        # Display utilities
â”‚   â””â”€â”€ llm_agent.py     # AI agent initialization (SQL + Python)
â”œâ”€â”€ data/                # CSV files for database
â”‚   â”œâ”€â”€ users.csv        # 100,000 user records
â”‚   â”œâ”€â”€ orders.csv       # 125,530 order records
â”‚   â”œâ”€â”€ order_items.csv  # 181,891 order item records
â”‚   â”œâ”€â”€ products.csv     # 29,120 product records
â”‚   â”œâ”€â”€ inventory_items.csv # 246,386 inventory records
â”‚   â”œâ”€â”€ distribution_centers.csv # 10 distribution center records
â”‚   â””â”€â”€ events.csv       # 1,012,244 event records
â””â”€â”€ README.md
```

**Note:** This structure follows Streamlit best practices with `streamlit_app.py` at the root for automatic detection during deployment.

---

## Testing Locally

### Prerequisites
- **Python 3.10** (recommended for compatibility)
- OpenAI API key
- Git

### Setup Instructions

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd text-to-sql-agent
   ```

2. **Create virtual environment with Python 3.10**
   ```bash
   # If you have Python 3.10 installed
   python3.10 -m venv venv
   
   # Activate the virtual environment
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   
   # Verify Python version
   python --version  # Should show Python 3.10.x
   ```
   
   **âš ï¸ Important**: Always use a virtual environment to avoid conflicts with system Python packages.

3. **Install dependencies in virtual environment**
   ```bash
   # Ensure venv is activated (you should see (venv) in your prompt)
   pip install --upgrade pip
   pip install -r requirements.txt
   ```
   
   **ğŸ’¡ Pro Tip**: All Python commands should be run inside the activated virtual environment.

4. **Configure secrets (Local)**
   
   Copy the example environment file and add your OpenAI API key:
   ```bash
   cp .env.example .env
   ```
   
   Edit `.env` and add your actual API key:
   ```bash
   OPENAI_API_KEY=sk-your-actual-api-key-here
   LLM_MODEL_NAME=gpt-4.1-2025-04-14
   DATABASE=ecommerce
   ```

   **âš ï¸ Important**: The `.env` file is already in `.gitignore` and will not be committed to version control.

5. **Set up the database (REQUIRED)**
   
   **âš ï¸ Important**: The database file is not included in the repository due to its large size (144MB). You must create it locally:
   
   ```bash
   # Ensure venv is activated (you should see (venv) in your prompt)
   python setup_database.py
   ```
   
   This will create the `ecommerce` database file with 7 tables populated from the CSV files in the `data/` directory:
   - **users**: 100,000 records
   - **orders**: 125,530 records  
   - **order_items**: 181,891 records
   - **products**: 29,120 records
   - **inventory_items**: 246,386 records
   - **distribution_centers**: 10 records
   - **events**: 1,012,244 records
   
   **Note**: The `ecommerce` database file is in `.gitignore` to avoid GitHub's 100MB file limit.

6. **Run the application in virtual environment**
   ```bash
   # Ensure venv is activated (you should see (venv) in your prompt)
   streamlit run streamlit_app.py
   ```

7. **Access the application**
   
   Open your browser to `http://localhost:8501`

### Testing Tips

- Test with simple queries first: "Show me the top 10 users by orders"
- Try visualization queries: "Plot the distribution of orders by month"
- Test conversation context: Ask follow-up questions
- Verify error handling: Try ambiguous or invalid queries

---

## Deploying to Streamlit Community Cloud

### Prerequisites
- GitHub account
- Streamlit Community Cloud account (free at [share.streamlit.io](https://share.streamlit.io))
- OpenAI API key

### Deployment Steps

1. **Push to GitHub**
   ```bash
   git add .
   git commit -m "Prepare for Streamlit deployment"
   git push origin main
   ```

3. **Deploy on Streamlit Cloud**
   
   a. Go to [share.streamlit.io](https://share.streamlit.io)
   
   b. Click "New app"
   
   c. Connect your GitHub repository
   
   d. Configure deployment:
      - **Repository**: Your repo URL
      - **Branch**: main
      - **Main file path**: `streamlit_app.py` (auto-detected)
      - **Python version**: 3.9+

4. **Configure Secrets**
   
   In Streamlit Cloud app settings:
   
   a. Click "Advanced settings" â†’ "Secrets"
   
   b. Add secrets in TOML format:
   ```toml
   OPENAI_API_KEY = "sk-your-actual-api-key-here"
   LLM_MODEL_NAME = "gpt-4.1-2025-04-14"
   DATABASE = "ecommerce"
   ```

5. **Deploy & Database Considerations**
   
   **For Demo/Testing (Current Setup):**
   - App automatically creates SQLite database from CSV files on first launch
   - Shows "Setting up database for first time..." spinner
   - **âš ï¸ Limitation**: Streamlit Cloud has ephemeral storage - database recreated on app restarts

   **For Production (Recommended):**
   
   Streamlit Cloud doesn't provide persistent database hosting. For production, consider:
   
   **Option 1: Cloud Database Services**
   - **PostgreSQL**: AWS RDS, Google Cloud SQL, Supabase
   - **MySQL**: PlanetScale, Railway, DigitalOcean
   - **Serverless**: Neon, Xata, Turso (SQLite-compatible)
   
   **Option 2: Update Connection String**
   ```python
   # In src/config.py, replace SQLite with cloud database
   DATABASE_URL = get_config("DATABASE_URL", "postgresql://user:pass@host:5432/dbname")
   # Then update src/llm_agent.py:
   db = SQLDatabase.from_uri(DATABASE_URL)
   ```
   
   **Option 3: Data Persistence Services**
   - Use external APIs for data storage
   - Connect to existing company databases
   - Cloud data warehouses (BigQuery, Snowflake)

   **Current setup works for demos - use external DB for production!**

---

## Secrets Management Guide

### How Configuration Works

The application uses a unified configuration system via `src/config.py` that automatically handles both local and cloud deployments:

**Priority Order:**
1. Environment variables from `.env` file (preferred for local development)
2. Streamlit secrets (for Streamlit Cloud deployment)
3. Default values

**Note:** You may see a "No secrets files found" message in local development - this is normal and can be ignored when using `.env` files.

### Local Development: .env File

1. **Create your `.env` file:**
   ```bash
   cp .env.example .env
   ```

2. **Add your credentials:**
   ```bash
   OPENAI_API_KEY=sk-your-actual-api-key-here
   LLM_MODEL_NAME=gpt-4.1-2025-04-14
   DATABASE=ecommerce
   ```

3. **Run the app:**
   ```bash
   streamlit run streamlit_app.py
   ```

The `.env` file is automatically loaded by `src/config.py` and is excluded from git by `.gitignore`.

### Streamlit Cloud Deployment: Secrets Manager

1. **Deploy your app** on [share.streamlit.io](https://share.streamlit.io)

2. **Add secrets** in app settings â†’ Advanced settings â†’ Secrets:
   ```toml
   OPENAI_API_KEY = "sk-your-production-key"
   LLM_MODEL_NAME = "gpt-4.1-2025-04-14"
   DATABASE = "ecommerce"
   ```

3. **Deploy** - No code changes needed! The same `src/config.py` automatically uses Streamlit secrets in cloud.

---

## Usage Examples

### Text Queries
```
"Show me the top 10 customers by total order value"
"What is the average order value by month?"
"How many returns do we have this quarter?"
```

### Visualization Queries
```
"Plot the distribution of orders by state"
"Create a chart showing monthly revenue trends"
"Graph the top 10 products by sales"
```

### Follow-up Queries
```
User: "Show me total sales by category"
Agent: [Returns data]
User: "Now plot that as a bar chart"  # Uses context from previous query
```

---

## Troubleshooting

### Common Issues

**1. "No OpenAI API key found"**
- Verify `.env` file exists and contains `OPENAI_API_KEY`
- Check API key format starts with `sk-`
- Ensure you ran `cp .env.example .env` and added your real key

**2. "Database connection error"**
- Ensure SQLite database exists and is accessible
- Check `DATABASE` value in `.env` file matches your database name

**3. "Module not found" errors**
- Run `pip install -r requirements.txt`
- Verify virtual environment is activated

**4. Visualization not rendering**
- Check that query includes visualization keywords
- Verify Plotly is installed
- Look for Python code syntax errors in logs

**5. Agent not responding**
- Check OpenAI API quota/billing
- Verify model name is correct
- Review Streamlit terminal logs for errors

**6. Python version conflicts**
- Use Python 3.10 (recommended): `python3.10 -m venv venv`
- Always activate virtual environment before running
- Check version: `python --version` should show 3.10.x
- If issues persist, delete `venv/` and recreate it

**7. "Wrong Python packages installed"**
- Ensure virtual environment is activated (you should see `(venv)` in terminal)
- Reinstall in venv: `pip install -r requirements.txt`
- Never install packages globally with `sudo pip install`

---

## Dependencies

The project uses 12 core dependencies (all others are transitive):

- **streamlit** - Web interface framework
- **Unidecode** - Text normalization for queries
- **langchain==0.2.10** - LLM agent framework
- **langchain-community==0.2.5** - SQL agents and chat models
- **langchain-experimental==0.0.61** - Python REPL tool
- **langchain-openai==0.1.17** - OpenAI chat models (compatible version)
- **langchainhub==0.1.20** - LangChain prompt templates
- **SQLAlchemy** - Database ORM for SQL operations
- **openai==1.30.5** - OpenAI API client (compatible version)
- **python-dotenv** - Environment variable management
- **plotly** - Interactive visualizations
- **pandas** - Data manipulation (required for database setup)
